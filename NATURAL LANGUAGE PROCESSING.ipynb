{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting a paragraph for referenece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"In Harry’s world fate works not only through powers and objects such as prophecies, the Sorting Hat, wands, and the Goblet of Fire, but also through people. Repeatedly, other characters decide Harry’s future for him, depriving him of freedom and choice. For example, before his eleventh birthday, the Dursleys control Harry’s life, keeping from him knowledge of his past and understanding of his identity (Sorcerer’s 49). In Harry Potter and the Chamber of Secrets, Dobby repeatedly assumes control over events by intercepting Ron’s and Hermione’s letters during the summer; by sealing the barrier to Platform 93⁄4, causing Harry to miss the Hogwarts Express; and by sending a Bludger after Harry in a Quidditch match, breaking his wrist. Yet again, in Harry Potter and the Prisoner of Azkaban, many adults intercede while attempting to protect Harry from perceived danger, as Snape observes: “Everyone from the Minister of Magic downward has been trying to keep famous Harry Potter safe from Sirius Black” (284). All these characters, as enactors of fate, unknowingly drive Harry toward his destiny by attempting to control or to direct his life, while themselves controlled and directed by fate.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aliasis for porterstemmer\n",
    "ps =PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aliasis for WordNetLemmatizer\n",
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(paragraph) # coverting a paragraph into sentences\n",
    "corpus = []                             # creating an empty list\n",
    "for i in range(len(sentence)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',sentence[i]) # replacing all the unnecesssary values with spaces in sentences[i]\n",
    "    review = review.lower()                     # converting it into lower\n",
    "    review = review.split()                     #split the words\n",
    "    #for word in review:\n",
    "        #if word not in set(stopwords.words('english')):            #for loop\n",
    "            #review=ps.stem(word)\n",
    "    review = [ps.stem(word) for word in review if word not in set(stopwords.words('english'))]  #List Comprehension\n",
    "    review = ','.join(review)\n",
    "    corpus.append(review)  # appending the words into corpus\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.27875308 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22858151 0.27875308 0.         0.         0.27875308\n",
      "  0.12373831 0.27875308 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.27875308 0.\n",
      "  0.         0.27875308 0.         0.         0.         0.27875308\n",
      "  0.         0.27875308 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27875308 0.         0.         0.         0.\n",
      "  0.         0.27875308 0.27875308 0.27875308 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32060456 0.39097435 0.         0.         0.39097435 0.39097435\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.39097435 0.39097435 0.\n",
      "  0.17355326 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.32060456 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.30122135 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.20853928 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.30122135\n",
      "  0.30122135 0.         0.         0.         0.30122135 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13371196 0.         0.         0.         0.30122135 0.\n",
      "  0.         0.24700582 0.30122135 0.         0.24700582 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.30122135 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.30122135 0.         0.         0.         0.         0.30122135\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.19390057 0.         0.         0.19390057\n",
      "  0.         0.         0.19390057 0.19390057 0.19390057 0.19390057\n",
      "  0.         0.         0.13423977 0.         0.         0.\n",
      "  0.         0.         0.19390057 0.         0.         0.\n",
      "  0.         0.         0.19390057 0.         0.         0.19390057\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.258217   0.         0.19390057 0.19390057 0.         0.\n",
      "  0.19390057 0.         0.         0.19390057 0.         0.\n",
      "  0.         0.19390057 0.         0.19390057 0.         0.\n",
      "  0.         0.         0.         0.19390057 0.15900124 0.\n",
      "  0.         0.         0.         0.19390057 0.15900124 0.19390057\n",
      "  0.         0.19390057 0.19390057 0.19390057 0.         0.\n",
      "  0.         0.         0.19390057 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.19390057 0.        ]\n",
      " [0.19684444 0.         0.         0.16141526 0.19684444 0.\n",
      "  0.         0.19684444 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.19684444 0.         0.\n",
      "  0.         0.         0.         0.19684444 0.         0.\n",
      "  0.         0.         0.         0.19684444 0.         0.\n",
      "  0.19684444 0.         0.         0.         0.         0.\n",
      "  0.26213736 0.         0.         0.         0.         0.19684444\n",
      "  0.         0.16141526 0.         0.         0.         0.19684444\n",
      "  0.19684444 0.         0.19684444 0.         0.         0.19684444\n",
      "  0.         0.         0.19684444 0.         0.32283052 0.\n",
      "  0.19684444 0.         0.19684444 0.         0.         0.\n",
      "  0.19684444 0.         0.         0.         0.19684444 0.19684444\n",
      "  0.         0.         0.         0.         0.19684444 0.\n",
      "  0.         0.         0.         0.         0.         0.19684444]\n",
      " [0.         0.         0.         0.20615875 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20615875 0.         0.34810676 0.         0.         0.\n",
      "  0.25140872 0.50281744 0.         0.         0.25140872 0.\n",
      "  0.         0.25140872 0.         0.         0.         0.\n",
      "  0.         0.41231749 0.         0.         0.         0.\n",
      "  0.11160016 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.20615875 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25140872 0.         0.\n",
      "  0.25140872 0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "Y = Tf.fit_transform(corpus).toarray()\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can train our model with dependent variable which we will be using in projects\n",
    "## eg: Look into Fake News Detection Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
